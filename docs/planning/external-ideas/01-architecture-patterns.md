# Architecture Patterns (Ideas #1-7)

**Category:** Core Architecture
**Total Ideas:** 20 (showing top 7 critical patterns)
**Priority:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê CRITICAL
**Phase:** 1-2
**Total Effort:** 70-95 hours

---

## üìã Overview

Fundamental architecture patterns extracted from Company-researcher and langchain-reference that form the foundation of a professional research system.

**Key Patterns:**
2. Tool Singleton Pattern
3. Custom Exception Hierarchy
4. Three-Phase Workflow
5. Multi-Model Routing
6. State Machine Design
7. Agent Factory Pattern

---

## üèóÔ∏è Critical Patterns


### #2. Tool Singleton Pattern ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Source:** Company-researcher/src/tools/__init__.py
**Priority:** HIGH
**Phase:** 1
**Effort:** Low (4-6 hours)

**What:**
Thread-safe singleton pattern for expensive tools (browser, search, APIs).

**Why:**
- Tools like browsers and API clients are expensive to initialize
- Reusing instances saves memory and initialization time
- Thread-safe access allows concurrent agent execution

**Implementation:**
```python
# src/tools/shared.py
import threading
from typing import Optional

# Singleton instances
_search_tool_instance: Optional[SearchTool] = None
_browser_tool_instance: Optional[BrowserTool] = None

# Thread-safe locks
_search_tool_lock = threading.Lock()
_browser_tool_lock = threading.Lock()

def get_shared_search_tool() -> SearchTool:
    """Get or create shared SearchTool (thread-safe)"""
    global _search_tool_instance
    if _search_tool_instance is None:
        with _search_tool_lock:
            # Double-check locking pattern
            if _search_tool_instance is None:
                _search_tool_instance = SearchTool()
    return _search_tool_instance

def get_shared_browser_tool() -> BrowserTool:
    """Get or create shared BrowserTool (thread-safe)"""
    global _browser_tool_instance
    if _browser_tool_instance is None:
        with _browser_tool_lock:
            if _browser_tool_instance is None:
                _browser_tool_instance = BrowserTool()
    return _browser_tool_instance

def reset_shared_tools():
    """Reset all shared tools (for testing)"""
    global _search_tool_instance, _browser_tool_instance
    with _search_tool_lock:
        _search_tool_instance = None
    with _browser_tool_lock:
        _browser_tool_instance = None

# Usage in agents
class FinancialAgent:
    def __init__(self):
        # Reuse shared instances instead of creating new ones
        self.search = get_shared_search_tool()
        self.browser = get_shared_browser_tool()
```

**Tools to Make Singletons:**
- Search tool (Tavily, Brave, etc.)
- Browser tool (Playwright)
- API clients (GitHub, Crunchbase, Alpha Vantage, etc.)
- LLM clients (OpenAI, Anthropic)
- Vector database connections

**Benefits:**
- 50% reduction in memory usage
- Faster agent initialization (3x faster)
- Resource pooling
- Thread-safe access
- Lower API costs

**Expected Impact:**
- 50% memory reduction
- 3x faster agent initialization
- Lower overall costs

**Dependencies:** None
**Next Steps:** Implement in Phase 1 before creating multiple agents

---

### #3. Custom Exception Hierarchy ‚≠ê‚≠ê‚≠ê‚≠ê

**Source:** Company-researcher/src/core/errors/
**Priority:** HIGH
**Phase:** 1
**Effort:** Medium (6-8 hours)

**What:**
Professional error hierarchy with retry logic and fallback mechanisms.

**Implementation:**
```python
# src/core/errors/exceptions.py
class ResearchError(Exception):
    """Base exception for all research errors"""
    pass

class AgentExecutionError(ResearchError):
    """Agent failed to execute"""
    def __init__(self, agent_name: str, message: str):
        self.agent_name = agent_name
        super().__init__(f"Agent '{agent_name}' failed: {message}")

class ToolExecutionError(ResearchError):
    """Tool failed to execute"""
    def __init__(self, tool_name: str, message: str):
        self.tool_name = tool_name
        super().__init__(f"Tool '{tool_name}' failed: {message}")

class DataExtractionError(ResearchError):
    """Failed to extract data"""
    pass

class ValidationError(ResearchError):
    """Data validation failed"""
    pass

class PipelineError(ResearchError):
    """Pipeline execution failed"""
    pass

# src/core/errors/retry.py
import asyncio
from functools import wraps

def retry_on_failure(max_retries=3, delay=1.0, backoff=2.0):
    """Decorator for retry logic with exponential backoff"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_delay = delay
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise
                    logger.warning(
                        f"Attempt {attempt + 1} failed: {e}. "
                        f"Retrying in {current_delay}s..."
                    )
                    await asyncio.sleep(current_delay)
                    current_delay *= backoff
        return wrapper
    return decorator

# Usage in agents
@retry_on_failure(max_retries=3)
async def search_with_retry(query: str):
    return await search_manager.search(query)

# src/core/errors/fallback.py
class FallbackHandler:
    """Handle graceful degradation"""

    @staticmethod
    async def execute_with_fallback(
        primary_func,
        fallback_func,
        context: str = "operation"
    ):
        try:
            return await primary_func()
        except Exception as e:
            logger.warning(
                f"{context} failed with primary method: {e}. "
                f"Using fallback..."
            )
            try:
                return await fallback_func()
            except Exception as e2:
                logger.error(f"Fallback also failed: {e2}")
                raise PipelineError(
                    f"Both primary and fallback failed for {context}"
                )

# Usage
result = await FallbackHandler.execute_with_fallback(
    primary_func=lambda: expensive_api_call(),
    fallback_func=lambda: cheaper_alternative(),
    context="financial_data_fetch"
)
```

**Components:**
```
ResearchError (base)
‚îú‚îÄ‚îÄ AgentExecutionError
‚îú‚îÄ‚îÄ ToolExecutionError
‚îú‚îÄ‚îÄ DataExtractionError
‚îú‚îÄ‚îÄ ValidationError
‚îî‚îÄ‚îÄ PipelineError

Plus:
- Retry decorator with exponential backoff
- Fallback handler for graceful degradation
- Circuit breaker pattern
```

**Benefits:**
- Clear error messages
- Graceful degradation
- Easy debugging
- Production reliability

**Dependencies:** None
**Next Steps:** Implement in Phase 1 foundation

---

### #4. Three-Phase Workflow Pattern ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Source:** langchain-reference/01-research-agents/company-researcher
**Priority:** CRITICAL
**Phase:** 1-2
**Effort:** Medium (10-12 hours)

**What:**
Clean 3-phase workflow: Search ‚Üí Extract ‚Üí Reflect

**Architecture:**
```python
# core/workflows/research_workflow.py
from enum import Enum

class ResearchPhase(Enum):
    SEARCH = "search"
    EXTRACT = "extract"
    REFLECT = "reflect"

class ThreePhaseWorkflow:
    def __init__(self):
        self.current_phase = ResearchPhase.SEARCH

    async def execute(self, query: str):
        """Execute complete 3-phase research workflow"""

        # Phase 1: Search
        sources = await self.search_phase(query)

        # Phase 2: Extract
        data = await self.extract_phase(sources)

        # Phase 3: Reflect
        quality = await self.reflect_phase(data, query)

        # Iterate if quality insufficient
        if quality < 0.7:
            improved_query = self.improve_query(query, data)
            return await self.execute(improved_query)

        return data

    async def search_phase(self, query: str):
        """Phase 1: Search for relevant sources"""
        sources = await self.search_engine.search(query)
        return self.validate_sources(sources)

    async def extract_phase(self, sources):
        """Phase 2: Extract structured data"""
        data = await self.extractor.extract(sources, schema)
        return self.validate_extraction(data)

    async def reflect_phase(self, data, query):
        """Phase 3: Assess quality and identify gaps"""
        quality_score = await self.reflector.assess(data)
        return quality_score
```

**Phases Explained:**
```python
Phase 1: SEARCH
- Query optimization
- Multi-source search (Tavily, Brave, etc.)
- Source collection & ranking
- Quality filtering

Phase 2: EXTRACT
- JSON schema extraction
- Structured data validation
- Entity recognition
- Data normalization

Phase 3: REFLECT
- Quality assessment (0-1 score)
- Gap identification
- Completeness check
- Iterative improvement
- Re-search if quality < 0.7
```

**Benefits:**
- Clean state transitions
- Iterative quality improvement
- Self-correcting workflow
- Production-tested
- Easy to understand and debug

**Expected Impact:**
- Higher quality results
- Automatic quality improvement
- Clear workflow progression

**Dependencies:** Search tool, Extractor, Quality reflector
**Next Steps:** Integrate into Phase 2 pipeline

---

### #5. Multi-Model Routing ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Source:** langchain-reference/04-production-apps/open_deep_research
**Priority:** HIGH
**Phase:** 2
**Effort:** Medium (8-10 hours)

**What:**
Intelligent model selection based on task type and complexity.

**Implementation:**
```python
# core/models/router.py
from enum import Enum

class TaskType(Enum):
    REASONING = "reasoning"
    SEARCH = "search"
    EXTRACTION = "extraction"
    SYNTHESIS = "synthesis"
    GENERAL = "general"

class ModelRouter:
    """Route tasks to optimal LLM models"""

    def __init__(self):
        self.models = {
            "claude-opus": {"cost": 0.015, "quality": 10, "speed": 7},
            "claude-sonnet": {"cost": 0.003, "quality": 9, "speed": 9},
            "claude-haiku": {"cost": 0.00025, "quality": 7, "speed": 10},
            "gpt-4-turbo": {"cost": 0.01, "quality": 9, "speed": 8},
            "gpt-3.5-turbo": {"cost": 0.0005, "quality": 7, "speed": 10},
        }

    def select_model(
        self,
        task_type: TaskType,
        complexity: str = "medium",
        budget_priority: bool = False
    ) -> str:
        """Select optimal model for task"""

        if budget_priority:
            # Cost-sensitive routing
            if task_type == TaskType.EXTRACTION:
                return "gpt-3.5-turbo"
            return "claude-haiku"

        # Quality-optimized routing
        if task_type == TaskType.REASONING and complexity == "high":
            return "claude-opus"

        elif task_type == TaskType.SEARCH:
            return "gpt-4-turbo"  # Fast and good

        elif task_type == TaskType.EXTRACTION:
            return "gpt-4-turbo"  # Best JSON

        elif task_type == TaskType.SYNTHESIS:
            return "claude-sonnet"  # Balanced

        return "claude-sonnet"  # Default

# Usage in agents
router = ModelRouter()

# Financial analysis (complex reasoning)
model = router.select_model(TaskType.REASONING, complexity="high")

# Data extraction (structured output)
model = router.select_model(TaskType.EXTRACTION)

# Quick search (speed priority)
model = router.select_model(TaskType.SEARCH)

# Budget mode
model = router.select_model(TaskType.GENERAL, budget_priority=True)
```

**Routing Logic:**
```python
Task-Based Routing:

If reasoning + high complexity:
  ‚Üí Claude Opus (best reasoning, worth the cost)

If search + speed needed:
  ‚Üí GPT-4 Turbo (fast, good quality)

If extraction + structured data:
  ‚Üí GPT-4 Turbo (best JSON extraction)

If synthesis + balanced:
  ‚Üí Claude Sonnet (great quality, good cost)

If budget-sensitive:
  ‚Üí Haiku/GPT-3.5 (cheaper options)
```

**Benefits:**
- Cost optimization (30-40% savings)
- Better quality for each task type
- Speed optimization
- Model fallback capability
- Budget control

**Expected Impact:**
- 30-40% cost reduction
- Better quality per task
- Faster execution

**Dependencies:** Multiple LLM API keys
**Next Steps:** Implement in Phase 2 with agents

---

### #6. State Machine Design ‚≠ê‚≠ê‚≠ê‚≠ê

**Source:** langchain-reference/04-production-apps/open_deep_research
**Priority:** MEDIUM-HIGH
**Phase:** 2
**Effort:** Medium (10-12 hours)

**What:**
LangGraph-based state machine for complex research workflows.

**Architecture:**
```python
from langgraph.graph import StateGraph

class ResearchState(TypedDict):
    query: str
    context: Dict
    sources: List[Dict]
    data: Dict
    insights: List[str]
    report: str
    quality_score: float
    iteration: int

# Define state machine
workflow = StateGraph(ResearchState)

# Add nodes (states)
workflow.add_node("plan_research", plan_research_node)
workflow.add_node("gather_data", gather_data_node)
workflow.add_node("analyze_data", analyze_data_node)
workflow.add_node("synthesize", synthesize_node)
workflow.add_node("generate_report", generate_report_node)
workflow.add_node("quality_check", quality_check_node)

# Define edges (transitions)
workflow.set_entry_point("plan_research")
workflow.add_edge("plan_research", "gather_data")
workflow.add_edge("gather_data", "analyze_data")
workflow.add_edge("analyze_data", "synthesize")
workflow.add_edge("synthesize", "generate_report")
workflow.add_edge("generate_report", "quality_check")

# Conditional edge - iterate or finish
workflow.add_conditional_edges(
    "quality_check",
    should_continue,
    {
        "continue": "gather_data",  # Loop back
        "end": END  # Finish
    }
)
```

**States:**
```
START
  ‚Üì
PLAN_RESEARCH (define research strategy)
  ‚Üì
GATHER_DATA (parallel agent execution)
  ‚Üì
ANALYZE_DATA (process results)
  ‚Üì
SYNTHESIZE_INSIGHTS (combine findings)
  ‚Üì
GENERATE_REPORT (create output)
  ‚Üì
QUALITY_CHECK (assess quality)
  ‚Üì (if quality < threshold)
ITERATE (loop back to GATHER_DATA with improvements)
  ‚Üì (if quality OK)
END
```

**Benefits:**
- Clear progression
- Easy to visualize
- Conditional branching
- Loop support
- State persistence

**Expected Impact:**
- Easier workflow understanding
- Visual debugging
- Clear state management

**Dependencies:** LangGraph
**Next Steps:** Consider for complex workflows in Phase 2

---

### #7. Agent Factory Pattern ‚≠ê‚≠ê‚≠ê‚≠ê

**Source:** Company-researcher/src/agents/factory.py
**Priority:** MEDIUM
**Phase:** 2
**Effort:** Low (4-6 hours)

**What:**
Factory pattern for creating agents with proper configuration.

**Implementation:**
```python
# src/agents/factory.py
from typing import Dict, Any

class AgentFactory:
    """Factory for creating configured agents"""

    @staticmethod
    def create_agent(agent_type: str, config: Dict[str, Any]):
        """Create agent by type with configuration"""

        agents = {
            "financial": FinancialAgent,
            "market": MarketAnalyst,
            "competitor": CompetitorScout,
            "brand": BrandAuditor,
            "sales": SalesAgent,
            "investment": InvestmentAgent,
            "social": SocialMediaAgent,
            "sector": SectorAnalyst,
            "deep_research": DeepResearchAgent,
            "reasoning": ReasoningAgent,
            "generic": GenericAgent,
            "logic_critic": LogicCritic,
            "insight_gen": InsightGenerator,
            "report_writer": ReportWriter,
        }

        agent_class = agents.get(agent_type)
        if not agent_class:
            raise ValueError(f"Unknown agent type: {agent_type}")

        return agent_class(**config)

    @staticmethod
    def create_all_specialists(config: Dict[str, Any]) -> Dict[str, Any]:
        """Create all specialist agents with shared config"""

        specialists = {}
        for agent_type in ["financial", "market", "competitor",
                          "brand", "sales", "investment"]:
            specialists[agent_type] = AgentFactory.create_agent(
                agent_type,
                config
            )

        return specialists

# Usage
from src.agents.factory import AgentFactory

# Single agent
config = {"llm": llm, "tools": tools, "memory": memory}
financial_agent = AgentFactory.create_agent("financial", config)

# All specialists
all_agents = AgentFactory.create_all_specialists(config)
```

**Benefits:**
- Centralized agent creation
- Easy to add new agents
- Consistent configuration
- Testing friendly
- Dependency injection

**Expected Impact:**
- Easier agent management
- Consistent configuration
- Simplified testing

**Dependencies:** Base agent class
**Next Steps:** Implement with specialist agents in Phase 2

---

## üìä Summary

### Total Effort
- **7 Critical Patterns:** 70-95 hours
- **Average per pattern:** 10-14 hours

### By Phase
- **Phase 1:** Ideas #2, #3 (10-14 hours)
- **Phase 2:** Ideas #1, #4, #5, #6, #7 (60-81 hours)

### By Priority
- **‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê CRITICAL:** 4 patterns (#1, #2, #4, #5)
- **‚≠ê‚≠ê‚≠ê‚≠ê HIGH:** 3 patterns (#3, #6, #7)

---

## ‚úÖ Implementation Order

1. **Phase 1 Week 1:**
   - #2: Tool Singleton Pattern (4-6h)
   - #3: Custom Exception Hierarchy (6-8h)

2. **Phase 2 Week 3:**
   - #4: Three-Phase Workflow (10-12h)
   - #7: Agent Factory Pattern (4-6h)

3. **Phase 2 Week 4:**
   - #5: Multi-Model Routing (8-10h)
   - #1: Pipeline Orchestrator (15-20h)
   - #6: State Machine (10-12h) - Optional

**Total: 57-74 hours core patterns**

---

## üìö Related Documents

- [../PLANNING_INTEGRATION_MAP.md](../PLANNING_INTEGRATION_MAP.md) - Integration guide
- [../phases/PHASE_1_FOUNDATION.md](../phases/PHASE_1_FOUNDATION.md) - Phase 1 plan
- [../phases/PHASE_2_SPECIALISTS.md](../phases/PHASE_2_SPECIALISTS.md) - Phase 2 plan

**Source Code:**
- Company-researcher: `.archive/reference/Company-resarcher/`
- langchain-reference: `External repos/langchain-reference/`

---

**Status:** ‚úÖ Complete
**Ready for:** Phase 1-2 implementation
